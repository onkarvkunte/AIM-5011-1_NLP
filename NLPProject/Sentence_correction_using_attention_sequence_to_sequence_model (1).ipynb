{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "id": "o3u462KOCgVC"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input,GRU,LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "import six\n",
    "from tensorflow.keras.utils import deserialize_keras_object\n",
    "from joblib import dump, load\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input,GRU,Embedding,Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, Dropout, GRU, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    " \n",
    "from tensorflow.keras.layers import concatenate, Lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "id": "UylqAaZMgCqT"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The data from ASL model is added to other similar data source to increasee the data quantity'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "id": "lOHI3gpgDT4Y"
   },
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "id": "82u6VlUGHc6Z"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('output.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT3wku7cDWv0",
    "outputId": "76967974-1e1a-48b0-cadc-e093b15b0692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape (2512, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Shape\",data.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3cvj0T5dHndE",
    "outputId": "426136b0-a6a0-4aa4-9e67-ed5cd870318e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1795 westh st rerorore</td>\n",
       "      <td>2796 west golden willow drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+39-313-5199</td>\n",
       "      <td>9734719887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>998-121-1662</td>\n",
       "      <td>4977236992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elle cororerin</td>\n",
       "      <td>reallyloud.co.uksimaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arilalallanges</td>\n",
       "      <td>kkaicd1.pixnet.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               prediction                    target_text\n",
       "0  1795 westh st rerorore  2796 west golden willow drive\n",
       "1            +39-313-5199                     9734719887\n",
       "2            998-121-1662                     4977236992\n",
       "3          elle cororerin         reallyloud.co.uksimaii\n",
       "4          arilalallanges             kkaicd1.pixnet.net"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary called column_mapping that maps old column names to new column names.\n",
    "column_mapping = {'prediction': 'SMS_TEXT', 'target_text': 'ENGLISH_TEXT'}\n",
    "\n",
    "# Use the rename() function on the 'data' DataFrame to rename columns as specified in the column_mapping dictionary.\n",
    "# The inplace=True parameter means that the changes are applied directly to the DataFrame 'data' without creating a new DataFrame.\n",
    "data.rename(columns=column_mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "id": "YtkKiz9AH_gY"
   },
   "outputs": [],
   "source": [
    "def preprocessing_steps(data):\n",
    "    # Applying the length on both sms_text and english_text and filtering the sentences based on length \n",
    "    # adding start token and end token for inputs and output dataframe\n",
    "    # '\\t'-> start token which represents the start of the sentence\n",
    "    # '\\n'-> end token which represents the end of the sentence.\n",
    "    # Removing the sms_length, english_length, and ENGLISH_TEXT and appending ENGLISH_INPUT, ENGLISH_OUTPUT for the decoder.\n",
    "    \n",
    "    data['sms_length'] = data['SMS_TEXT'].str.split().apply(len)\n",
    "    data['eng_length'] = data['ENGLISH_TEXT'].str.split().apply(len)\n",
    "    \n",
    "    # Filtering based on sentence length\n",
    "    data = data[data['sms_length'] <= 39]\n",
    "    data = data[data['eng_length'] <= 40]\n",
    "    \n",
    "    # Adding start and end tokens\n",
    "    data['ENGLISH_INPUT'] = '<start> ' + data['ENGLISH_TEXT'].astype(str)\n",
    "    data['ENGLISH_OUTPUT'] = data['ENGLISH_TEXT'].astype(str) + ' <end>'\n",
    "    \n",
    "    # Dropping unnecessary columns\n",
    "    data = data.drop(['sms_length', 'eng_length', 'ENGLISH_TEXT'], axis=1)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7aV6JUIKrxfi",
    "outputId": "76a11896-3913-4966-f615-05373e73f4fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2503, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data using preprocessing_steps function\n",
    "preprocessed_data = preprocessing_steps(data)\n",
    "\n",
    "# Print the shape of the preprocessed data\n",
    "print(preprocessed_data.shape)\n",
    "\n",
    "# Add '<end>' tag to the first English input\n",
    "preprocessed_data.iloc[0]['ENGLISH_INPUT'] = str(preprocessed_data.iloc[0]['ENGLISH_INPUT']) + ' <end>'\n",
    "\n",
    "# Commenting out the line that modifies the English output\n",
    "# preprocessed_data.iloc[0]['ENGLISH_OUTPUT'] = '\\t ' + str(preprocessed_data.iloc[0]['ENGLISH_OUTPUT']) + ' \\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "A_ydJK_8r1D2",
    "outputId": "f8ee4488-29d7-40d6-81a4-60beb4a69bf2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS_TEXT</th>\n",
       "      <th>ENGLISH_INPUT</th>\n",
       "      <th>ENGLISH_OUTPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1795 westh st rerorore</td>\n",
       "      <td>&lt;start&gt; 2796 west golden willow drive</td>\n",
       "      <td>2796 west golden willow drive &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>+39-313-5199</td>\n",
       "      <td>&lt;start&gt; 9734719887</td>\n",
       "      <td>9734719887 &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>998-121-1662</td>\n",
       "      <td>&lt;start&gt; 4977236992</td>\n",
       "      <td>4977236992 &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elle cororerin</td>\n",
       "      <td>&lt;start&gt; reallyloud.co.uksimaii</td>\n",
       "      <td>reallyloud.co.uksimaii &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arilalallanges</td>\n",
       "      <td>&lt;start&gt; kkaicd1.pixnet.net</td>\n",
       "      <td>kkaicd1.pixnet.net &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SMS_TEXT                          ENGLISH_INPUT  \\\n",
       "0  1795 westh st rerorore  <start> 2796 west golden willow drive   \n",
       "1            +39-313-5199                     <start> 9734719887   \n",
       "2            998-121-1662                     <start> 4977236992   \n",
       "3          elle cororerin         <start> reallyloud.co.uksimaii   \n",
       "4          arilalallanges             <start> kkaicd1.pixnet.net   \n",
       "\n",
       "                        ENGLISH_OUTPUT  \n",
       "0  2796 west golden willow drive <end>  \n",
       "1                     9734719887 <end>  \n",
       "2                     4977236992 <end>  \n",
       "3         reallyloud.co.uksimaii <end>  \n",
       "4             kkaicd1.pixnet.net <end>  "
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6r1rQNa_sIWk",
    "outputId": "79f4bef1-08ad-45e8-9f5b-af40363d5fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2477, 3)\n",
      "(26, 3)\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary module for splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the preprocessed_data into training and testing sets\n",
    "train_data, test_data = train_test_split(preprocessed_data, test_size=0.01, random_state=42)\n",
    "\n",
    "# Print the shape of the training and testing sets\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "2qstuEo4KgK7",
    "outputId": "50ea1d2c-70b9-46c1-c5cf-d3918c8b6227"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS_TEXT</th>\n",
       "      <th>ENGLISH_INPUT</th>\n",
       "      <th>ENGLISH_OUTPUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Haven sleep yet? How have you been recently? H...</td>\n",
       "      <td>&lt;start&gt; Haven't slept yet? How have you been r...</td>\n",
       "      <td>Haven't slept yet? How have you been recently?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>Hey u in e lt oredi?Im on my way..</td>\n",
       "      <td>&lt;start&gt; Hey, are you in the LT already? I'm on...</td>\n",
       "      <td>Hey, are you in the LT already? I'm on my way....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>No money to cut lor... Haha, no la, juz feel l...</td>\n",
       "      <td>&lt;start&gt; I have no money to cut. Haha, no, I ju...</td>\n",
       "      <td>I have no money to cut. Haha, no, I just feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>Hi.. How was calculus? Feel that e lec is not ...</td>\n",
       "      <td>&lt;start&gt; Hi. How was calculus? Feel that the le...</td>\n",
       "      <td>Hi. How was calculus? Feel that the lecture is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>maintenance technician hw abt u?</td>\n",
       "      <td>&lt;start&gt; Maintenance technician. How about you?</td>\n",
       "      <td>Maintenance technician. How about you? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>Anyone free today?Wanna go ecp?or expo?</td>\n",
       "      <td>&lt;start&gt; Anyone free today? Want to go to ecp? ...</td>\n",
       "      <td>Anyone free today? Want to go to ecp? or expo?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>Do u have linear algebra past papers' sol??</td>\n",
       "      <td>&lt;start&gt; Do you have linear algebra past papers...</td>\n",
       "      <td>Do you have linear algebra past papers' soluti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>Haha... Ü mean mich din join her meh?</td>\n",
       "      <td>&lt;start&gt; Haha. You mean Mich Din joins her?</td>\n",
       "      <td>Haha. You mean Mich Din joins her? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>Hi its Kate how is your evening? I hope  i can...</td>\n",
       "      <td>&lt;start&gt; Hi, it's Kate, how is your evening? I ...</td>\n",
       "      <td>Hi, it's Kate, how is your evening? I hope I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>Hey... My lesson tmr at 440 leh... Tt means i ...</td>\n",
       "      <td>&lt;start&gt; Hey. My lesson tomorrow at 4:40. That ...</td>\n",
       "      <td>Hey. My lesson tomorrow at 4:40. That means I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2477 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               SMS_TEXT  \\\n",
       "1136  Haven sleep yet? How have you been recently? H...   \n",
       "2333                 Hey u in e lt oredi?Im on my way..   \n",
       "858   No money to cut lor... Haha, no la, juz feel l...   \n",
       "929   Hi.. How was calculus? Feel that e lec is not ...   \n",
       "568                    maintenance technician hw abt u?   \n",
       "...                                                 ...   \n",
       "1641            Anyone free today?Wanna go ecp?or expo?   \n",
       "1097        Do u have linear algebra past papers' sol??   \n",
       "1132              Haha... Ü mean mich din join her meh?   \n",
       "1296  Hi its Kate how is your evening? I hope  i can...   \n",
       "861   Hey... My lesson tmr at 440 leh... Tt means i ...   \n",
       "\n",
       "                                          ENGLISH_INPUT  \\\n",
       "1136  <start> Haven't slept yet? How have you been r...   \n",
       "2333  <start> Hey, are you in the LT already? I'm on...   \n",
       "858   <start> I have no money to cut. Haha, no, I ju...   \n",
       "929   <start> Hi. How was calculus? Feel that the le...   \n",
       "568      <start> Maintenance technician. How about you?   \n",
       "...                                                 ...   \n",
       "1641  <start> Anyone free today? Want to go to ecp? ...   \n",
       "1097  <start> Do you have linear algebra past papers...   \n",
       "1132         <start> Haha. You mean Mich Din joins her?   \n",
       "1296  <start> Hi, it's Kate, how is your evening? I ...   \n",
       "861   <start> Hey. My lesson tomorrow at 4:40. That ...   \n",
       "\n",
       "                                         ENGLISH_OUTPUT  \n",
       "1136  Haven't slept yet? How have you been recently?...  \n",
       "2333  Hey, are you in the LT already? I'm on my way....  \n",
       "858   I have no money to cut. Haha, no, I just feel ...  \n",
       "929   Hi. How was calculus? Feel that the lecture is...  \n",
       "568        Maintenance technician. How about you? <end>  \n",
       "...                                                 ...  \n",
       "1641  Anyone free today? Want to go to ecp? or expo?...  \n",
       "1097  Do you have linear algebra past papers' soluti...  \n",
       "1132           Haha. You mean Mich Din joins her? <end>  \n",
       "1296  Hi, it's Kate, how is your evening? I hope I c...  \n",
       "861   Hey. My lesson tomorrow at 4:40. That means I ...  \n",
       "\n",
       "[2477 rows x 3 columns]"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvnBfck6sLVb",
    "outputId": "a35fcf08-e72c-44c1-b466-0dd0992889d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS_TEXT\n",
      "English text\n"
     ]
    }
   ],
   "source": [
    "# Create a tokenizer for the 'SMS_TEXT' column\n",
    "tokenizer = Tokenizer(filters=\" \", char_level=False, lower=False)\n",
    "print(\"SMS_TEXT\")\n",
    "# Fit the tokenizer on the 'SMS_TEXT' values in the training data\n",
    "tokenizer.fit_on_texts(train_data['SMS_TEXT'].values)\n",
    "\n",
    "# Create a tokenizer for the 'ENGLISH_INPUT' column\n",
    "print(\"English text\")\n",
    "tokenizer_e = Tokenizer(filters=\" \", char_level=False, lower=False)\n",
    "# Fit the tokenizer on the 'ENGLISH_INPUT' values in the training data\n",
    "tokenizer_e.fit_on_texts(train_data['ENGLISH_INPUT'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tokenizer on the English output data\n",
    "tokenizer_e.fit_on_texts(train_data['ENGLISH_OUTPUT'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hXLBniTsOgF",
    "outputId": "58e2f526-4d01-4214-9c85-2178173f8a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7815\n",
      "5464\n"
     ]
    }
   ],
   "source": [
    "# Calculate the vocabulary size for the encoder\n",
    "encoder_vocab_size = len(tokenizer.word_index.keys())\n",
    "print(encoder_vocab_size)\n",
    "\n",
    "# Calculate the vocabulary size for the decoder\n",
    "decoder_vocab_size = len(tokenizer_e.word_index.keys())\n",
    "print(decoder_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kkKj7AfcGAU",
    "outputId": "8d1a5335-357a-4ea6-f8ab-04adc7586336"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u': 1,\n",
       " 'to': 2,\n",
       " 'i': 3,\n",
       " 'the': 4,\n",
       " 'I': 5,\n",
       " 'a': 6,\n",
       " 'at': 7,\n",
       " 'me': 8,\n",
       " 'go': 9,\n",
       " 'my': 10,\n",
       " 'ü': 11,\n",
       " 'in': 12,\n",
       " 'is': 13,\n",
       " 'e': 14,\n",
       " 'for': 15,\n",
       " 'you': 16,\n",
       " 'U': 17,\n",
       " 'can': 18,\n",
       " 'got': 19,\n",
       " 'on': 20,\n",
       " 'ur': 21,\n",
       " 'of': 22,\n",
       " 'not': 23,\n",
       " 'are': 24,\n",
       " '2': 25,\n",
       " 'n': 26,\n",
       " 'so': 27,\n",
       " 'Hey': 28,\n",
       " '4': 29,\n",
       " 'So': 30,\n",
       " 'or': 31,\n",
       " 'will': 32,\n",
       " 'we': 33,\n",
       " 'time': 34,\n",
       " 'be': 35,\n",
       " 'have': 36,\n",
       " 'it': 37,\n",
       " 'wan': 38,\n",
       " 'lor...': 39,\n",
       " \"I'm\": 40,\n",
       " 'meet': 41,\n",
       " 'r': 42,\n",
       " 'and': 43,\n",
       " 'do': 44,\n",
       " 'no': 45,\n",
       " 'if': 46,\n",
       " 'all': 47,\n",
       " 'dun': 48,\n",
       " 'come': 49,\n",
       " 'still': 50,\n",
       " 'Ü': 51,\n",
       " 'your': 52,\n",
       " 'then': 53,\n",
       " 'one': 54,\n",
       " 'but': 55,\n",
       " 'get': 56,\n",
       " 'going': 57,\n",
       " 'up': 58,\n",
       " 'like': 59,\n",
       " 'out': 60,\n",
       " 'But': 61,\n",
       " 'Hi': 62,\n",
       " 'wat': 63,\n",
       " 'b': 64,\n",
       " 'how': 65,\n",
       " 'ask': 66,\n",
       " 'den': 67,\n",
       " 'goin': 68,\n",
       " \"i'm\": 69,\n",
       " 'home': 70,\n",
       " 'this': 71,\n",
       " 'with': 72,\n",
       " 'when': 73,\n",
       " 'call': 74,\n",
       " 'w': 75,\n",
       " 'think': 76,\n",
       " 'Haha...': 77,\n",
       " 'now': 78,\n",
       " 'she': 79,\n",
       " 'that': 80,\n",
       " 'free': 81,\n",
       " 'back': 82,\n",
       " 'as': 83,\n",
       " 'buy': 84,\n",
       " 'la...': 85,\n",
       " 'see': 86,\n",
       " 'How': 87,\n",
       " 'abt': 88,\n",
       " 'just': 89,\n",
       " 'they': 90,\n",
       " 'juz': 91,\n",
       " 'take': 92,\n",
       " 'need': 93,\n",
       " 'Then': 94,\n",
       " 'too': 95,\n",
       " 'her': 96,\n",
       " 'more': 97,\n",
       " 'wanna': 98,\n",
       " 'where': 99,\n",
       " 'there': 100,\n",
       " 'was': 101,\n",
       " 'Ok': 102,\n",
       " 'No': 103,\n",
       " 'We': 104,\n",
       " 'Can': 105,\n",
       " \"i'll\": 106,\n",
       " 'say': 107,\n",
       " 'Wat': 108,\n",
       " 'an': 109,\n",
       " 'liao...': 110,\n",
       " 'from': 111,\n",
       " 'tt': 112,\n",
       " 'he': 113,\n",
       " 'Den': 114,\n",
       " 'later': 115,\n",
       " 'da': 116,\n",
       " 'ah...': 117,\n",
       " 'My': 118,\n",
       " ':)': 119,\n",
       " 'oredi...': 120,\n",
       " 'Haha': 121,\n",
       " 'after': 122,\n",
       " '?': 123,\n",
       " 'If': 124,\n",
       " 'day': 125,\n",
       " 'cos': 126,\n",
       " 'bring': 127,\n",
       " 'ard': 128,\n",
       " 'only': 129,\n",
       " 'know': 130,\n",
       " 'late': 131,\n",
       " 'leh...': 132,\n",
       " 'im': 133,\n",
       " 'make': 134,\n",
       " 'noe': 135,\n",
       " 'oso': 136,\n",
       " 'c': 137,\n",
       " 'find': 138,\n",
       " 'msg': 139,\n",
       " 'by': 140,\n",
       " 'very': 141,\n",
       " 'want': 142,\n",
       " 'Oh': 143,\n",
       " 'u?': 144,\n",
       " \"I'll\": 145,\n",
       " 'cant': 146,\n",
       " 'what': 147,\n",
       " 'good': 148,\n",
       " 'wif': 149,\n",
       " 'quite': 150,\n",
       " 'Haha,': 151,\n",
       " 'tis': 152,\n",
       " 'thk': 153,\n",
       " 'Hey...': 154,\n",
       " 'tmr': 155,\n",
       " 'some': 156,\n",
       " 'liao': 157,\n",
       " 'intro': 158,\n",
       " 'really': 159,\n",
       " 'am': 160,\n",
       " 'reach': 161,\n",
       " 'Not': 162,\n",
       " 'jus': 163,\n",
       " 'long': 164,\n",
       " 'look': 165,\n",
       " 'ñ': 166,\n",
       " 'v': 167,\n",
       " 'dunno': 168,\n",
       " 's': 169,\n",
       " 'R': 170,\n",
       " 'next': 171,\n",
       " 'You': 172,\n",
       " 'ok': 173,\n",
       " 'Where': 174,\n",
       " 'did': 175,\n",
       " 'its': 176,\n",
       " 'wait': 177,\n",
       " 'now?': 178,\n",
       " 'din': 179,\n",
       " 'help': 180,\n",
       " 'ya': 181,\n",
       " 'Me': 182,\n",
       " 'new': 183,\n",
       " '...': 184,\n",
       " 'doing': 185,\n",
       " 'eat': 186,\n",
       " 'lunch': 187,\n",
       " 'also': 188,\n",
       " 'fren': 189,\n",
       " 'care': 190,\n",
       " 'wat...': 191,\n",
       " 'frm': 192,\n",
       " 'Eh': 193,\n",
       " 'already': 194,\n",
       " 'sch': 195,\n",
       " 'y': 196,\n",
       " 'much': 197,\n",
       " 'first': 198,\n",
       " 'lor.': 199,\n",
       " 'yr': 200,\n",
       " 'any': 201,\n",
       " 'dinner': 202,\n",
       " 'chat': 203,\n",
       " 'outside': 204,\n",
       " 'now...': 205,\n",
       " 'coming': 206,\n",
       " 'A': 207,\n",
       " 'Hmmm...': 208,\n",
       " 'hav': 209,\n",
       " '1': 210,\n",
       " 'tell': 211,\n",
       " 'watch': 212,\n",
       " 'k.': 213,\n",
       " \"it's\": 214,\n",
       " 'change': 215,\n",
       " 'our': 216,\n",
       " 'lei...': 217,\n",
       " 'sis': 218,\n",
       " 'enjoy': 219,\n",
       " 'nd': 220,\n",
       " 'Im': 221,\n",
       " 'reply': 222,\n",
       " 'Call': 223,\n",
       " 'today': 224,\n",
       " 'ah?': 225,\n",
       " 'early': 226,\n",
       " 'nt': 227,\n",
       " 'cut': 228,\n",
       " 'way': 229,\n",
       " 'dat': 230,\n",
       " 'show': 231,\n",
       " 'nice': 232,\n",
       " '3': 233,\n",
       " 'Got': 234,\n",
       " 'lor': 235,\n",
       " 'work': 236,\n",
       " 'tink': 237,\n",
       " 'dont': 238,\n",
       " 'Dun': 239,\n",
       " 'gd': 240,\n",
       " 'had': 241,\n",
       " 'Ya': 242,\n",
       " 'Hope': 243,\n",
       " 'bus': 244,\n",
       " 'been': 245,\n",
       " 'feel': 246,\n",
       " 'end': 247,\n",
       " 'Dunno': 248,\n",
       " 'haf': 249,\n",
       " 'u...': 250,\n",
       " 'hey': 251,\n",
       " 'wana': 252,\n",
       " 'He': 253,\n",
       " \"It's\": 254,\n",
       " 'now.': 255,\n",
       " 'sms': 256,\n",
       " 'here': 257,\n",
       " 'Yup...': 258,\n",
       " 'Y': 259,\n",
       " 'sure': 260,\n",
       " 'ür': 261,\n",
       " 'hope': 262,\n",
       " 'last': 263,\n",
       " 'Tmr': 264,\n",
       " 'Okay...': 265,\n",
       " '!': 266,\n",
       " 'must': 267,\n",
       " 'around': 268,\n",
       " 'rite...': 269,\n",
       " 'stay': 270,\n",
       " 'off': 271,\n",
       " 'again': 272,\n",
       " 'Cos': 273,\n",
       " 'Oh...': 274,\n",
       " 'finish': 275,\n",
       " 'mind': 276,\n",
       " 'hp': 277,\n",
       " 'saw': 278,\n",
       " 'Or': 279,\n",
       " 'At': 280,\n",
       " 'too...': 281,\n",
       " 'us': 282,\n",
       " 'd': 283,\n",
       " 'place': 284,\n",
       " 'Ur': 285,\n",
       " '12': 286,\n",
       " 'down': 287,\n",
       " 'She': 288,\n",
       " 'lah...': 289,\n",
       " 'than': 290,\n",
       " 'him': 291,\n",
       " 'book': 292,\n",
       " 'right?': 293,\n",
       " 'Take': 294,\n",
       " 'lesson': 295,\n",
       " 'having': 296,\n",
       " 'play': 297,\n",
       " 'me...': 298,\n",
       " 'la,': 299,\n",
       " 'hi': 300,\n",
       " 'Thk': 301,\n",
       " 'Hee...': 302,\n",
       " 'lect': 303,\n",
       " 'ok.': 304,\n",
       " 'few': 305,\n",
       " 'bad': 306,\n",
       " 'time...': 307,\n",
       " 'didnt': 308,\n",
       " 'hair': 309,\n",
       " 'muz': 310,\n",
       " 'Good': 311,\n",
       " 'ppl': 312,\n",
       " 'mi': 313,\n",
       " 'working': 314,\n",
       " 'went': 315,\n",
       " 'stuff': 316,\n",
       " 'yet?': 317,\n",
       " 'gonna': 318,\n",
       " 'time?': 319,\n",
       " 'le': 320,\n",
       " 'it?': 321,\n",
       " 'orchard': 322,\n",
       " '&': 323,\n",
       " 'coz': 324,\n",
       " 'big': 325,\n",
       " 'haven': 326,\n",
       " 'Huh...': 327,\n",
       " 'let': 328,\n",
       " 'é': 329,\n",
       " 'today?': 330,\n",
       " 'ME': 331,\n",
       " 'la..': 332,\n",
       " 'put': 333,\n",
       " 'other': 334,\n",
       " 'tmr?': 335,\n",
       " 'mean': 336,\n",
       " '.': 337,\n",
       " 'b4': 338,\n",
       " 'havent': 339,\n",
       " 'THE': 340,\n",
       " 'today...': 341,\n",
       " 'wont': 342,\n",
       " 'try': 343,\n",
       " 'cya': 344,\n",
       " 'not?': 345,\n",
       " 'never': 346,\n",
       " 'lar...': 347,\n",
       " 'who': 348,\n",
       " 'class': 349,\n",
       " 'Yupz...': 350,\n",
       " 'send': 351,\n",
       " 'nite': 352,\n",
       " 'Hee': 353,\n",
       " 'What': 354,\n",
       " 'rite?': 355,\n",
       " 'Okie': 356,\n",
       " 'lk': 357,\n",
       " 'short': 358,\n",
       " 'Haha.': 359,\n",
       " 'use': 360,\n",
       " 'study': 361,\n",
       " 'life': 362,\n",
       " 'another': 363,\n",
       " 'ah,': 364,\n",
       " 'sat': 365,\n",
       " 't': 366,\n",
       " 'before': 367,\n",
       " 'drivin': 368,\n",
       " 'confirm': 369,\n",
       " 'anything': 370,\n",
       " 'nus': 371,\n",
       " 'always': 372,\n",
       " 'someone': 373,\n",
       " 'sweet': 374,\n",
       " 'pass': 375,\n",
       " 'hard': 376,\n",
       " 'hse': 377,\n",
       " 'number': 378,\n",
       " 'bit': 379,\n",
       " 'shop': 380,\n",
       " 'lot': 381,\n",
       " 'oso...': 382,\n",
       " 'one...': 383,\n",
       " 'Go': 384,\n",
       " 'frens': 385,\n",
       " 'done': 386,\n",
       " 'mon': 387,\n",
       " 'm': 388,\n",
       " 'Help': 389,\n",
       " 'Is': 390,\n",
       " 'sorry': 391,\n",
       " 'pay': 392,\n",
       " 'meeting': 393,\n",
       " 'Oh,': 394,\n",
       " 'maybe': 395,\n",
       " 'house': 396,\n",
       " 'mayb': 397,\n",
       " 'Did': 398,\n",
       " 'great': 399,\n",
       " 'Sorry': 400,\n",
       " 'there?': 401,\n",
       " '..': 402,\n",
       " 'driving': 403,\n",
       " 'were': 404,\n",
       " 'might': 405,\n",
       " 'Juz': 406,\n",
       " 'oredi': 407,\n",
       " 'days': 408,\n",
       " 'things': 409,\n",
       " 'When': 410,\n",
       " 'pls': 411,\n",
       " 'lor,': 412,\n",
       " 'lah.': 413,\n",
       " 'mrt': 414,\n",
       " 'Dont': 415,\n",
       " 'gal': 416,\n",
       " 'Just': 417,\n",
       " 'wk': 418,\n",
       " 'fun': 419,\n",
       " 'They': 420,\n",
       " 'dinner...': 421,\n",
       " 'And': 422,\n",
       " 'near': 423,\n",
       " 'fore': 424,\n",
       " 'give': 425,\n",
       " 'Ask': 426,\n",
       " 'those': 427,\n",
       " 'Okie...': 428,\n",
       " 'Lea': 429,\n",
       " 'told': 430,\n",
       " 'Haven': 431,\n",
       " 'sleep': 432,\n",
       " 'money': 433,\n",
       " 'check': 434,\n",
       " 'tat': 435,\n",
       " 'email': 436,\n",
       " '6': 437,\n",
       " 'Cya': 438,\n",
       " 'phone': 439,\n",
       " 'Have': 440,\n",
       " 'guys': 441,\n",
       " 'which': 442,\n",
       " 'into': 443,\n",
       " 'Really': 444,\n",
       " 'shld': 445,\n",
       " 'far': 446,\n",
       " 'love': 447,\n",
       " 'The': 448,\n",
       " 'havin': 449,\n",
       " 'Eh...': 450,\n",
       " 'can?': 451,\n",
       " 'rest': 452,\n",
       " 'said': 453,\n",
       " 'ok...': 454,\n",
       " 'it...': 455,\n",
       " 'IM': 456,\n",
       " 'IS': 457,\n",
       " 'Joey:': 458,\n",
       " 'bought': 459,\n",
       " 'over': 460,\n",
       " 'keep': 461,\n",
       " 'well': 462,\n",
       " 'hall': 463,\n",
       " 'forget': 464,\n",
       " 'workin': 465,\n",
       " 'better': 466,\n",
       " 'leh': 467,\n",
       " 'same': 468,\n",
       " 'should': 469,\n",
       " 'me?': 470,\n",
       " 'name': 471,\n",
       " 'me.': 472,\n",
       " 'wake': 473,\n",
       " 'huh...': 474,\n",
       " 'many': 475,\n",
       " 'cannot': 476,\n",
       " \"don't\": 477,\n",
       " 'doin': 478,\n",
       " 'until': 479,\n",
       " 'E': 480,\n",
       " 'pple': 481,\n",
       " 'doing?': 482,\n",
       " 'dear': 483,\n",
       " 'online': 484,\n",
       " 'his': 485,\n",
       " 'male': 486,\n",
       " 'wun': 487,\n",
       " 'Mayb': 488,\n",
       " 'Still': 489,\n",
       " 'bk': 490,\n",
       " 'Do': 491,\n",
       " 'u.': 492,\n",
       " 'slp': 493,\n",
       " 'thing': 494,\n",
       " 'friends': 495,\n",
       " 'Cant': 496,\n",
       " 'leh.': 497,\n",
       " 'how?': 498,\n",
       " 'nothing': 499,\n",
       " 'thn': 500,\n",
       " 'about': 501,\n",
       " 'camp': 502,\n",
       " 'sci': 503,\n",
       " 'notes': 504,\n",
       " 'came': 505,\n",
       " 'Of': 506,\n",
       " 'tmr...': 507,\n",
       " 'neva': 508,\n",
       " 'HI': 509,\n",
       " 'MY': 510,\n",
       " 'leave': 511,\n",
       " 'go?': 512,\n",
       " 'ing': 513,\n",
       " 'else': 514,\n",
       " 'lotsa': 515,\n",
       " 'left': 516,\n",
       " 'Anyway,': 517,\n",
       " 'lah,': 518,\n",
       " 'wish': 519,\n",
       " 'happy': 520,\n",
       " 'Maybe': 521,\n",
       " 'birthday': 522,\n",
       " 'join': 523,\n",
       " 'shall': 524,\n",
       " 'bout': 525,\n",
       " 'pick': 526,\n",
       " 'wil': 527,\n",
       " 'leh,': 528,\n",
       " 'west': 529,\n",
       " 'not...': 530,\n",
       " 'job': 531,\n",
       " 'k': 532,\n",
       " 'dog': 533,\n",
       " 'photo': 534,\n",
       " 'Hey,': 535,\n",
       " 'soon': 536,\n",
       " 'blue': 537,\n",
       " 'town': 538,\n",
       " 'going?': 539,\n",
       " 'com': 540,\n",
       " 'On': 541,\n",
       " 'now..': 542,\n",
       " 'able': 543,\n",
       " 'fri': 544,\n",
       " 'All': 545,\n",
       " 'later...': 546,\n",
       " 'xin': 547,\n",
       " 'Yup': 548,\n",
       " 'Yun': 549,\n",
       " 'Later': 550,\n",
       " 'IN': 551,\n",
       " 'part': 552,\n",
       " 'tv': 553,\n",
       " 'week': 554,\n",
       " 'exams': 555,\n",
       " '1st': 556,\n",
       " 'haha..': 557,\n",
       " 'afternoon': 558,\n",
       " 'time.': 559,\n",
       " 'Happy': 560,\n",
       " 'too.': 561,\n",
       " 'Are': 562,\n",
       " 'start': 563,\n",
       " 'Wanna': 564,\n",
       " 'dreams': 565,\n",
       " 'tml': 566,\n",
       " 'fine': 567,\n",
       " 'K': 568,\n",
       " 'something': 569,\n",
       " 'worry': 570,\n",
       " \"there's\": 571,\n",
       " 'ah.': 572,\n",
       " 'them': 573,\n",
       " 'movie': 574,\n",
       " 'Elaine': 575,\n",
       " 'called': 576,\n",
       " 'de': 577,\n",
       " 'comin': 578,\n",
       " 'lah': 579,\n",
       " 'la': 580,\n",
       " 'nvr': 581,\n",
       " 'Anyway': 582,\n",
       " 'tot': 583,\n",
       " 'Yup.': 584,\n",
       " 'liao.': 585,\n",
       " 'tired': 586,\n",
       " 'tai': 587,\n",
       " 'bugis': 588,\n",
       " 'ma...': 589,\n",
       " 'nxt': 590,\n",
       " '=)': 591,\n",
       " 'st': 592,\n",
       " 'parents': 593,\n",
       " 'drive': 594,\n",
       " 'It': 595,\n",
       " 'gotta': 596,\n",
       " 'means': 597,\n",
       " 'interested': 598,\n",
       " 'save': 599,\n",
       " 'bbq': 600,\n",
       " 'Huh': 601,\n",
       " 'already...': 602,\n",
       " 'seat': 603,\n",
       " 'busy': 604,\n",
       " 'ma': 605,\n",
       " 'both': 606,\n",
       " 'shopping': 607,\n",
       " 'till': 608,\n",
       " 'k?': 609,\n",
       " 'leona': 610,\n",
       " 'forgot': 611,\n",
       " 'Gee...': 612,\n",
       " 'already.': 613,\n",
       " 'has': 614,\n",
       " 'nvm': 615,\n",
       " 'dad': 616,\n",
       " 'ù': 617,\n",
       " 'walk': 618,\n",
       " 'first.': 619,\n",
       " 'yet.': 620,\n",
       " 'soon.': 621,\n",
       " 'year': 622,\n",
       " 'guess': 623,\n",
       " 'yun': 624,\n",
       " 'exam': 625,\n",
       " 'TO': 626,\n",
       " 'Nope...': 627,\n",
       " 'fetch': 628,\n",
       " 'Hi!': 629,\n",
       " 'now,': 630,\n",
       " \"That's\": 631,\n",
       " 'female': 632,\n",
       " 'Kaiez...': 633,\n",
       " \"I've\": 634,\n",
       " 'may': 635,\n",
       " 'yet': 636,\n",
       " 'miss': 637,\n",
       " 'watching': 638,\n",
       " 'UP': 639,\n",
       " 'not.': 640,\n",
       " 'thought': 641,\n",
       " 'U?': 642,\n",
       " 'ok?': 643,\n",
       " 'test': 644,\n",
       " 'almost': 645,\n",
       " \"how's\": 646,\n",
       " 'school': 647,\n",
       " 'again...': 648,\n",
       " 'che': 649,\n",
       " 'actually': 650,\n",
       " \"Wat's\": 651,\n",
       " 'bishan': 652,\n",
       " 'choose': 653,\n",
       " 'sit': 654,\n",
       " \"wat's\": 655,\n",
       " 'wrong': 656,\n",
       " 'Will': 657,\n",
       " 'out...': 658,\n",
       " 'leh?': 659,\n",
       " 'UR': 660,\n",
       " 'Hello': 661,\n",
       " 'drinks': 662,\n",
       " 'veri': 663,\n",
       " 'disturb': 664,\n",
       " 'mine': 665,\n",
       " 'talk': 666,\n",
       " 'Now': 667,\n",
       " '=5': 668,\n",
       " 'enough': 669,\n",
       " 'old': 670,\n",
       " 'real': 671,\n",
       " ',': 672,\n",
       " 'Hmmm....': 673,\n",
       " \"How's\": 674,\n",
       " 'talking': 675,\n",
       " 'Study': 676,\n",
       " 'coffee': 677,\n",
       " 'proj': 678,\n",
       " 'Hey!': 679,\n",
       " 'Mine': 680,\n",
       " 'sad': 681,\n",
       " 'today.': 682,\n",
       " 'school?': 683,\n",
       " 'win': 684,\n",
       " 'ans': 685,\n",
       " 'HEY': 686,\n",
       " 'May': 687,\n",
       " 'Pls': 688,\n",
       " 'dance': 689,\n",
       " 'Same': 690,\n",
       " 'chinese': 691,\n",
       " 'chat?': 692,\n",
       " 'Okay.': 693,\n",
       " \"i've\": 694,\n",
       " 'understand': 695,\n",
       " 'east': 696,\n",
       " 'eng': 697,\n",
       " 'open': 698,\n",
       " 'you.': 699,\n",
       " 'found': 700,\n",
       " 'right': 701,\n",
       " 'haha': 702,\n",
       " 'Today': 703,\n",
       " 'abit': 704,\n",
       " 'ware': 705,\n",
       " 'cum': 706,\n",
       " 'damn': 707,\n",
       " '5': 708,\n",
       " 'late...': 709,\n",
       " 'ah': 710,\n",
       " 'lovely': 711,\n",
       " 'hows': 712,\n",
       " 'Its': 713,\n",
       " 'smth': 714,\n",
       " 'Okay': 715,\n",
       " 'li': 716,\n",
       " 'Ay': 717,\n",
       " 'fone': 718,\n",
       " 'past': 719,\n",
       " 'NOT': 720,\n",
       " 'can...': 721,\n",
       " 'day...': 722,\n",
       " 'den...': 723,\n",
       " 'tut': 724,\n",
       " '8': 725,\n",
       " 'Coz': 726,\n",
       " 'thanks': 727,\n",
       " 'sunday': 728,\n",
       " 'decide': 729,\n",
       " 'WAS': 730,\n",
       " 'C': 731,\n",
       " 'here...': 732,\n",
       " 'sent': 733,\n",
       " 'darlin': 734,\n",
       " 'collect': 735,\n",
       " 'thgt': 736,\n",
       " 'izzit?': 737,\n",
       " 'uni': 738,\n",
       " 'non': 739,\n",
       " 'N': 740,\n",
       " 'LOVE': 741,\n",
       " 'add': 742,\n",
       " 'cheese': 743,\n",
       " 'diff': 744,\n",
       " 'lor..': 745,\n",
       " 'Lk': 746,\n",
       " 'monkey': 747,\n",
       " 'Very': 748,\n",
       " 'case': 749,\n",
       " 'u..': 750,\n",
       " 'hv': 751,\n",
       " 'tonight': 752,\n",
       " 'Ok...': 753,\n",
       " 'table': 754,\n",
       " 'In': 755,\n",
       " 'Hehe..': 756,\n",
       " 'duno': 757,\n",
       " 'alone': 758,\n",
       " 'Muz': 759,\n",
       " 'lecture': 760,\n",
       " 'go...': 761,\n",
       " 'night': 762,\n",
       " 'tel': 763,\n",
       " 'Huh?': 764,\n",
       " 'comp': 765,\n",
       " 'food': 766,\n",
       " 'OR': 767,\n",
       " 'n.n': 768,\n",
       " 'no.': 769,\n",
       " 'wat?': 770,\n",
       " 'anot?': 771,\n",
       " 'studying': 772,\n",
       " 'would': 773,\n",
       " 'pls?': 774,\n",
       " 'receive': 775,\n",
       " 'then.': 776,\n",
       " 'lots': 777,\n",
       " 'yet...': 778,\n",
       " 'discuss': 779,\n",
       " 'break': 780,\n",
       " 'feeling': 781,\n",
       " 'thurs': 782,\n",
       " '10': 783,\n",
       " 'bf': 784,\n",
       " 'then...': 785,\n",
       " 'it,': 786,\n",
       " 'guy': 787,\n",
       " 'Hmm...': 788,\n",
       " 'out.': 789,\n",
       " 'Try': 790,\n",
       " 'taxi': 791,\n",
       " 'bot': 792,\n",
       " 'Ya...': 793,\n",
       " 'late.': 794,\n",
       " \"He's\": 795,\n",
       " 'mei': 796,\n",
       " 'thin': 797,\n",
       " 'Really...': 798,\n",
       " 'Why': 799,\n",
       " \"u'll\": 800,\n",
       " 'huh?': 801,\n",
       " 'Nope': 802,\n",
       " 'up.': 803,\n",
       " 'watchin': 804,\n",
       " 'morning': 805,\n",
       " 'sign': 806,\n",
       " 'tonight?': 807,\n",
       " \"who's\": 808,\n",
       " 'fr': 809,\n",
       " 'later?': 810,\n",
       " 'sun': 811,\n",
       " 'la.': 812,\n",
       " 'prob': 813,\n",
       " 'Anyone': 814,\n",
       " 'sell': 815,\n",
       " 'learn': 816,\n",
       " 'pink': 817,\n",
       " 'anyway': 818,\n",
       " 'bt': 819,\n",
       " 'close': 820,\n",
       " 'along': 821,\n",
       " 'enuff': 822,\n",
       " 'min': 823,\n",
       " 'Which': 824,\n",
       " 'colour': 825,\n",
       " 'cute': 826,\n",
       " 'exercise': 827,\n",
       " 'present': 828,\n",
       " 'o': 829,\n",
       " 'ex': 830,\n",
       " 'together': 831,\n",
       " 'also.': 832,\n",
       " 'without': 833,\n",
       " 'kind': 834,\n",
       " 'shuhui': 835,\n",
       " 'took': 836,\n",
       " 'seats': 837,\n",
       " 'dunno...': 838,\n",
       " 'even': 839,\n",
       " 'Get': 840,\n",
       " 'instead': 841,\n",
       " 'oredi?': 842,\n",
       " 'stil': 843,\n",
       " 'celebrate': 844,\n",
       " 'please': 845,\n",
       " 'studyin': 846,\n",
       " 'interested?': 847,\n",
       " 'plan': 848,\n",
       " '7': 849,\n",
       " 'u!': 850,\n",
       " 'Enjoy': 851,\n",
       " 'little': 852,\n",
       " 'price': 853,\n",
       " 'lesson...': 854,\n",
       " 'gettin': 855,\n",
       " 'Thanx': 856,\n",
       " 'aft': 857,\n",
       " 'èn': 858,\n",
       " 'reached': 859,\n",
       " 'trip': 860,\n",
       " '25': 861,\n",
       " 'TIME': 862,\n",
       " 'reaching': 863,\n",
       " 'FOR': 864,\n",
       " \"he's\": 865,\n",
       " 'lt': 866,\n",
       " 'Feel': 867,\n",
       " 'hw': 868,\n",
       " 'acct': 869,\n",
       " 'applied': 870,\n",
       " 'papers': 871,\n",
       " 'AT': 872,\n",
       " 'airport': 873,\n",
       " 'body': 874,\n",
       " 'Whats': 875,\n",
       " 'id': 876,\n",
       " 'heart': 877,\n",
       " 'say...': 878,\n",
       " 'away': 879,\n",
       " 'shit': 880,\n",
       " 'card': 881,\n",
       " 'started': 882,\n",
       " 'Ok,': 883,\n",
       " 'two': 884,\n",
       " 'WERE': 885,\n",
       " 'OF': 886,\n",
       " 'Sure': 887,\n",
       " 'one..': 888,\n",
       " 'can.': 889,\n",
       " 'do...': 890,\n",
       " '1245': 891,\n",
       " 'Meet': 892,\n",
       " 'okie': 893,\n",
       " 'lessons': 894,\n",
       " 'nt?': 895,\n",
       " 'Going': 896,\n",
       " 'meh...': 897,\n",
       " 'eat...': 898,\n",
       " 'line': 899,\n",
       " 'wad': 900,\n",
       " 'le..': 901,\n",
       " 'ok,': 902,\n",
       " 'being': 903,\n",
       " 'This': 904,\n",
       " 'dinner.': 905,\n",
       " 're': 906,\n",
       " 'cn': 907,\n",
       " 'Hee-': 908,\n",
       " 'here,': 909,\n",
       " 'using': 910,\n",
       " 'rem': 911,\n",
       " 'handphone': 912,\n",
       " 'pretty': 913,\n",
       " 'office': 914,\n",
       " 'wk...': 915,\n",
       " 'anything...': 916,\n",
       " 'cuz': 917,\n",
       " 'course': 918,\n",
       " 'somewhere': 919,\n",
       " 'mind...': 920,\n",
       " 'NO': 921,\n",
       " 'Kaiez,': 922,\n",
       " 'Hello...': 923,\n",
       " 'finished': 924,\n",
       " 'Kate': 925,\n",
       " 'meh?': 926,\n",
       " 'Thought': 927,\n",
       " 'mum': 928,\n",
       " 'fun...': 929,\n",
       " 'wuz': 930,\n",
       " 'sick': 931,\n",
       " 'pubbin': 932,\n",
       " 'game': 933,\n",
       " 'bday': 934,\n",
       " 'sian': 935,\n",
       " 'Was': 936,\n",
       " 'DO': 937,\n",
       " 'because': 938,\n",
       " 'managed': 939,\n",
       " 'been?': 940,\n",
       " 'ON': 941,\n",
       " 'Thgt': 942,\n",
       " 'ah!': 943,\n",
       " 'lazy': 944,\n",
       " 'Yar': 945,\n",
       " 'ar': 946,\n",
       " 'thats': 947,\n",
       " 'liao..': 948,\n",
       " 'Nvr': 949,\n",
       " 'bored': 950,\n",
       " 'half': 951,\n",
       " 'luck': 952,\n",
       " 'jobs': 953,\n",
       " 'less': 954,\n",
       " 'mth': 955,\n",
       " 'already?': 956,\n",
       " 'remember': 957,\n",
       " 'stand': 958,\n",
       " 'since': 959,\n",
       " 'used': 960,\n",
       " 'yourself': 961,\n",
       " 'tomorrow': 962,\n",
       " 'alone.': 963,\n",
       " 'shd': 964,\n",
       " 'you...': 965,\n",
       " 'asked': 966,\n",
       " 'okay...': 967,\n",
       " 'num': 968,\n",
       " 'here.': 969,\n",
       " 'ch': 970,\n",
       " 'earlier': 971,\n",
       " \"can't\": 972,\n",
       " 'matter': 973,\n",
       " 'moon': 974,\n",
       " 'back?': 975,\n",
       " 'centre': 976,\n",
       " 'nv': 977,\n",
       " 'so...': 978,\n",
       " 'slightly': 979,\n",
       " 'cond': 980,\n",
       " 'hour': 981,\n",
       " 'ger': 982,\n",
       " 'fire': 983,\n",
       " 'dinner?': 984,\n",
       " 'linear': 985,\n",
       " 'haha,': 986,\n",
       " 'treat': 987,\n",
       " 'IVE': 988,\n",
       " 'WITH': 989,\n",
       " 'first...': 990,\n",
       " 'turn': 991,\n",
       " 'bash': 992,\n",
       " 'car': 993,\n",
       " 'there...': 994,\n",
       " 'news': 995,\n",
       " 'home.': 996,\n",
       " 'most': 997,\n",
       " 'thur': 998,\n",
       " 'room...': 999,\n",
       " 'meet?': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "id": "pvGXhLtgsBGx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "id": "tex1A1d6mqIW"
   },
   "outputs": [],
   "source": [
    "# class Dataset:\n",
    "#     def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
    "#         self.encoder_inps = data['italian'].values\n",
    "#         self.decoder_inps = data['d_english_input'].values\n",
    "#         self.decoder_outs = data['d_english_output'].values\n",
    "#         self.tknizer_eng = tknizer_eng\n",
    "#         self.tknizer_ita = tknizer_ita\n",
    "#         self.max_len = max_len\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "#         self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "#         self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "#         self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "#         self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "#         self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "#         return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "#     def __len__(self): \n",
    "#         return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "# class Dataloder(tf.keras.utils.Sequence):    \n",
    "#     def __init__(self, dataset, batch_size=1):\n",
    "#         self.dataset = dataset\n",
    "#         self.batch_size = batch_size\n",
    "#         self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         start = i * self.batch_size\n",
    "#         stop = (i + 1) * self.batch_size\n",
    "#         data = []\n",
    "#         for j in range(start, stop):\n",
    "#             data.append(self.dataset[j])\n",
    "\n",
    "#         batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "#         # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
    "#         return tuple([[batch[0],batch[1]],batch[2]])\n",
    "\n",
    "#     def __len__(self):  # your model.fit_gen requires this function\n",
    "#         return len(self.indexes) // self.batch_size\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdjHPdPxJavM"
   },
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder model -- That takes a input sequence and returns output sequence\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
    "\n",
    "        # Initialize Embedding layer\n",
    "        # Initialize Encoder LSTM layer\n",
    "        super().__init__()\n",
    "\n",
    "        # Creating an Embedding layer for input vocabulary\n",
    "        self.e_embed = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length)\n",
    "        self.lstm_size = lstm_size\n",
    "        \n",
    "        # Creating an LSTM layer for the encoder\n",
    "        self.e_lstm = LSTM(lstm_size, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "        '''\n",
    "        This function takes a sequence input and the initial states of the encoder.\n",
    "        Pass the input_sequence input to the Embedding layer, Pass the embedding layer output to encoder_lstm\n",
    "        returns -- encoder_output, last time step's hidden and cell state\n",
    "        '''\n",
    "        # Passing the input sequence through the embedding layer\n",
    "        embedding = self.e_embed(input_sequence)\n",
    "\n",
    "        # Passing the embedded sequence through the LSTM layer\n",
    "        output_state, enc_h, enc_c = self.e_lstm(embedding)\n",
    "\n",
    "        return output_state, enc_h, enc_c\n",
    "\n",
    "    def initialize_states(self, batch_size):\n",
    "        '''\n",
    "        Given a batch size it will return initial hidden state and initial cell state.\n",
    "        If batch size is 32- Hidden state is zeros of size [32, lstm_units], cell state zeros is of size [32, lstm_units]\n",
    "        '''\n",
    "        # Initializing the initial hidden and cell states with zeros\n",
    "        return [tf.zeros((batch_size, self.lstm_size)), tf.zeros((batch_size, self.lstm_size))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Class that calculates scores based on the scoring_function using Bahdanau attention mechanism.\n",
    "    '''\n",
    "    def __init__(self, scoring_function, att_units):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.scoring_function = scoring_function\n",
    "\n",
    "        if self.scoring_function == 'dot':\n",
    "            # Initialize variables needed for Dot score function here\n",
    "            self.dot = tf.keras.layers.Dot(axes=(1, 2))\n",
    "            pass\n",
    "        elif scoring_function == 'general':\n",
    "            # Initialize variables needed for General score function here\n",
    "            self.w = Dense(att_units)\n",
    "            self.dot = tf.keras.layers.Dot(axes=(1, 2))\n",
    "            pass\n",
    "        elif scoring_function == 'concat':\n",
    "            # Initialize variables needed for Concat score function here\n",
    "            self.w1 = Dense(att_units)\n",
    "            self.w2 = Dense(att_units)\n",
    "            self.v = Dense(1)\n",
    "            pass\n",
    "\n",
    "    def call(self, decoder_hidden_state, encoder_output):\n",
    "        '''\n",
    "        Attention mechanism takes two inputs: current step -- decoder_hidden_state and all the encoder_outputs.\n",
    "        * Based on the scoring function, we find the score or similarity between decoder_hidden_state and encoder_output.\n",
    "        * Multiply the score function with your encoder_outputs to get the context vector.\n",
    "        * Function returns context vector and attention weights (softmax - scores).\n",
    "        '''\n",
    "        decoder_hidden_state = tf.expand_dims(decoder_hidden_state, 1)\n",
    "        if self.scoring_function == 'dot':\n",
    "            # Implement Dot score function here\n",
    "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), encoder_output]), (0, 2, 1))\n",
    "            pass\n",
    "        elif self.scoring_function == 'general':\n",
    "            # Implement General score function here\n",
    "            mulpy = self.w(encoder_output)\n",
    "            score = tf.transpose(self.dot([tf.transpose(decoder_hidden_state, (0, 2, 1)), mulpy]), (0, 2, 1),)\n",
    "            pass\n",
    "        elif self.scoring_function == 'concat':\n",
    "            inte = self.w1(decoder_hidden_state) + self.w2(encoder_output)\n",
    "            tan = tf.nn.tanh(inte)\n",
    "            score = self.v(tan)\n",
    "\n",
    "        att_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = att_weights * encoder_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, att_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.Model):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, input_length, dec_units, score_fun, att_units):\n",
    "        # Initialize decoder embedding layer, LSTM, and any other objects needed\n",
    "        super(OneStepDecoder, self).__init__()\n",
    "        self.dec_embed = Embedding(input_dim=tar_vocab_size, output_dim=embedding_dim)\n",
    "        self.lstm = LSTM(dec_units, return_sequences=True, return_state=True)\n",
    "        self.attention = Attention(scoring_function=score_fun, att_units=att_units)\n",
    "        self.den = Dense(tar_vocab_size)\n",
    "\n",
    "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
    "        '''\n",
    "        One step decoder mechanism step by step:\n",
    "        A. Pass the input_to_decoder to the embedding layer and then get the output (batch_size, 1, embedding_dim)\n",
    "        B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
    "        C. Concatenate the context vector with the output from Step A\n",
    "        D. Pass the output from Step C to LSTM/GRU and get the decoder output and states (hidden and cell state)\n",
    "        E. Pass the decoder output to the dense layer (vocab size) and store the result into output.\n",
    "        F. Return the states from Step D, output from Step E, attention weights from Step B, context vector.\n",
    "        '''\n",
    "        embd = self.dec_embed(input_to_decoder)\n",
    "        context_vec, attention_weights = self.attention(state_h, encoder_output)\n",
    "\n",
    "        f_inp = tf.concat([tf.expand_dims(context_vec, 1), embd], axis=-1)\n",
    "        # print(f_inp.shape)\n",
    "        out, dec_h, dec_c = self.lstm(f_inp, [state_h, state_c])\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        output = self.den(out)\n",
    "\n",
    "        return output, dec_h, dec_c, attention_weights, context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
    "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "      super(Decoder, self).__init__()\n",
    "      self.input_length = input_length\n",
    "      self.out_vocab_size = out_vocab_size\n",
    "      self.oneStepDecoder = OneStepDecoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "      self.out_vocab_size = out_vocab_size\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
    "\n",
    "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
    "        #Create a tensor array as shown in the reference notebook\n",
    "        \n",
    "        #Iterate till the length of the decoder input\n",
    "            # Call onestepdecoder for each token in decoder_input\n",
    "            # Store the output in tensorarray\n",
    "        # Return the tensor array\n",
    "        # outputs = tf.TensorArray(dtype =  tf.float32, size= input_to_decoder.shape[1])\n",
    "        outputs = tf.TensorArray(dtype =  tf.float32, size= tf.shape(input_to_decoder)[1])\n",
    "\n",
    "        \n",
    "        for timestep in range(tf.shape(input_to_decoder)[1]):\n",
    "\n",
    "            output, decoder_hidden_state, decoder_cell_state, _, _ = self.oneStepDecoder(input_to_decoder[:, timestep:timestep+1],\n",
    "                                                                                          encoder_output,decoder_hidden_state,decoder_cell_state)                                                                                            \n",
    "                                                                                             \n",
    "                                                                                             \n",
    "            # Store the output in tensorarray\n",
    "            outputs = outputs.write(timestep, output)\n",
    "        # Return the tensor array\n",
    "        outputs = tf.transpose(outputs.stack(), (1, 0, 2))\n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,inp_vocab_size, out_vocab_size,input_length, enc_units,embedding_dim, dec_units, max_len, score_fun, att_units, batch_size):\n",
    "    #Intialize objects from encoder decoder\n",
    "    super(encoder_decoder, self).__init__()\n",
    "    self.encoder = Encoder(inp_vocab_size= inp_vocab_size +1, embedding_size=embedding_dim, lstm_size= att_units,input_length= max_len)\n",
    "    self.decoder = Decoder(out_vocab_size +1, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "  \n",
    "  def call(self,data):\n",
    "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
    "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
    "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
    "    # return the decoder output\n",
    "    e_inp, d_inp = data[0], data[1]\n",
    "    # print(data[0].shape)\n",
    "    # print(data[1].shape)\n",
    "\n",
    "\n",
    "    initial_state = self.encoder.initialize_states(self.batch_size)\n",
    "\n",
    "    e_output, enc_h, enc_c = self.encoder(e_inp,initial_state)\n",
    "    outputs = tf.TensorArray(dtype = tf.float32, size= 20)\n",
    "        \n",
    "    dec_h = enc_h\n",
    "    dec_c = enc_c\n",
    "    # print(dec_h.shape)\n",
    "    output=self.decoder(d_inp,e_output, dec_h, dec_c)\n",
    "  \n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRxB-FDMJWL"
   },
   "source": [
    "<font color='blue'>**Custom loss function**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "id": "QY_3izrXMs8y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Define the Adam optimizer for training\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define the Sparse Categorical Crossentropy loss function\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# Define a custom loss function that takes the targets and logits\n",
    "def custom_lossfunction(targets, logits):\n",
    "    # Create a mask to ignore loss for padded zeros\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    \n",
    "    # Calculate the original loss\n",
    "    loss_ = loss_object(targets, logits)\n",
    "    \n",
    "    # Apply the mask to the loss\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    # Calculate the mean of the loss considering only non-padded values\n",
    "    return tf.reduce_mean(loss_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QlbWAqNNlqe"
   },
   "source": [
    "<font color='blue'>**Training**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtZUQF2NuZE"
   },
   "source": [
    "Implement dot function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "id": "XtYqvcqvufUH"
   },
   "outputs": [],
   "source": [
    "# Creating training and testing datasets using the 'Dataset' class\n",
    "train_dataset = Dataset(train_data, tokenizer, tokenizer_e, 39, 40)\n",
    "test_dataset = Dataset(test_data, tokenizer, tokenizer_e, 39, 40)\n",
    "\n",
    "# Creating dataloaders for training and testing using the 'Dataloder' class\n",
    "train_dataloader = Dataloder(train_dataset, batch_size=64)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "id": "1Za9GYu6u9SS"
   },
   "outputs": [],
   "source": [
    "# model = encoder_decoder(len(encoder_vocabluary), len(decoder_vocabluary),input_length, lstm_size, embedding_dim, att_units, max_len, 'dot', att_units, batch_size)\n",
    "# model.compile(optimizer = 'Adam', loss = custom_lossfunction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "id": "Aw4jhKeI8FDI"
   },
   "outputs": [],
   "source": [
    "# Import the backend module from the tensorflow.keras library\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define a custom accuracy function that takes two arguments: y_true (true labels) and y_pred (predicted labels)\n",
    "def accuracy(y_true, y_pred):\n",
    "\n",
    "    # Convert the predicted labels into the format of the float32 data type\n",
    "    pred_value = K.cast(K.argmax(y_pred, axis=-1), dtype='float32')\n",
    "    \n",
    "    # Compare the true labels with the predicted labels and convert the results into the format of the float32 data type\n",
    "    true_value = K.cast(K.equal(y_true, pred_value), dtype='float32')\n",
    "\n",
    "    # Create a mask that identifies the positions where the true labels are greater than 0 (where data is present)\n",
    "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
    "    \n",
    "    # Calculate the sum of correctly predicted values by multiplying the mask with the true_value\n",
    "    n_correct = K.sum(mask * true_value)\n",
    "    \n",
    "    # Calculate the total number of valid data points by summing the mask values\n",
    "    n_total = K.sum(mask)\n",
    "    \n",
    "    # Return the ratio of correctly predicted values to the total number of valid data points as the accuracy\n",
    "    return n_correct / n_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "id": "DMyAx1q7vT5e"
   },
   "outputs": [],
   "source": [
    "# Setting the size of the LSTM layer\n",
    "lstm_size = 100\n",
    "\n",
    "# Setting the dimension of the embedding layer\n",
    "embedding_dim = 128\n",
    "\n",
    "# Defining the number of attention units\n",
    "att_units = 100\n",
    "\n",
    "# Setting the number of units in the decoder layer\n",
    "dec_units = 100\n",
    "\n",
    "# Setting the batch size for training\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thk0nRrjuhV8",
    "outputId": "70681ca0-6db3-4f2d-d171-53184a024052"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 [==============================] - 10s 210ms/step - loss: 2.3642 - accuracy: 0.0779 - val_loss: 1.3186 - val_accuracy: 0.1287\n",
      "Epoch 2/30\n",
      "38/38 [==============================] - 8s 207ms/step - loss: 2.2296 - accuracy: 0.0838 - val_loss: 1.3147 - val_accuracy: 0.1345\n",
      "Epoch 3/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 2.1762 - accuracy: 0.0875 - val_loss: 1.2450 - val_accuracy: 0.1404\n",
      "Epoch 4/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 2.0214 - accuracy: 0.1050 - val_loss: 1.1654 - val_accuracy: 0.1520\n",
      "Epoch 5/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 1.8663 - accuracy: 0.1455 - val_loss: 1.0967 - val_accuracy: 0.1930\n",
      "Epoch 6/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 1.7307 - accuracy: 0.1732 - val_loss: 1.0652 - val_accuracy: 0.1988\n",
      "Epoch 7/30\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 1.6284 - accuracy: 0.1909 - val_loss: 1.0526 - val_accuracy: 0.2047\n",
      "Epoch 8/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 1.5296 - accuracy: 0.2124 - val_loss: 1.0351 - val_accuracy: 0.2164\n",
      "Epoch 9/30\n",
      "38/38 [==============================] - 8s 212ms/step - loss: 1.4414 - accuracy: 0.2313 - val_loss: 1.0354 - val_accuracy: 0.2105\n",
      "Epoch 10/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 1.3604 - accuracy: 0.2514 - val_loss: 1.0231 - val_accuracy: 0.2339\n",
      "Epoch 11/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 1.2746 - accuracy: 0.2751 - val_loss: 1.0251 - val_accuracy: 0.2281\n",
      "Epoch 12/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 1.2006 - accuracy: 0.2981 - val_loss: 1.0224 - val_accuracy: 0.2164\n",
      "Epoch 13/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 1.1255 - accuracy: 0.3286 - val_loss: 1.0196 - val_accuracy: 0.2339\n",
      "Epoch 14/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 1.0558 - accuracy: 0.3588 - val_loss: 1.0239 - val_accuracy: 0.2222\n",
      "Epoch 15/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 0.9911 - accuracy: 0.3890 - val_loss: 1.0256 - val_accuracy: 0.2398\n",
      "Epoch 16/30\n",
      "38/38 [==============================] - 8s 213ms/step - loss: 0.9327 - accuracy: 0.4141 - val_loss: 1.0211 - val_accuracy: 0.2515\n",
      "Epoch 17/30\n",
      "38/38 [==============================] - 8s 219ms/step - loss: 0.8700 - accuracy: 0.4465 - val_loss: 1.0280 - val_accuracy: 0.2398\n",
      "Epoch 18/30\n",
      "38/38 [==============================] - 8s 215ms/step - loss: 0.8162 - accuracy: 0.4723 - val_loss: 1.0343 - val_accuracy: 0.2398\n",
      "Epoch 19/30\n",
      "38/38 [==============================] - 8s 214ms/step - loss: 0.7693 - accuracy: 0.4960 - val_loss: 1.0528 - val_accuracy: 0.2339\n",
      "Epoch 20/30\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.7267 - accuracy: 0.5167 - val_loss: 1.0502 - val_accuracy: 0.2515\n",
      "Epoch 21/30\n",
      "38/38 [==============================] - 8s 207ms/step - loss: 0.6838 - accuracy: 0.5432 - val_loss: 1.0568 - val_accuracy: 0.2398\n",
      "Epoch 22/30\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.6427 - accuracy: 0.5673 - val_loss: 1.0631 - val_accuracy: 0.2632\n",
      "Epoch 23/30\n",
      "38/38 [==============================] - 8s 208ms/step - loss: 0.6028 - accuracy: 0.5917 - val_loss: 1.0827 - val_accuracy: 0.2573\n",
      "Epoch 24/30\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 0.5675 - accuracy: 0.6139 - val_loss: 1.0880 - val_accuracy: 0.2632\n",
      "Epoch 25/30\n",
      "38/38 [==============================] - 8s 212ms/step - loss: 0.5349 - accuracy: 0.6350 - val_loss: 1.1138 - val_accuracy: 0.2573\n",
      "Epoch 26/30\n",
      "38/38 [==============================] - 8s 213ms/step - loss: 0.5066 - accuracy: 0.6545 - val_loss: 1.1229 - val_accuracy: 0.2456\n",
      "Epoch 27/30\n",
      "38/38 [==============================] - 8s 216ms/step - loss: 0.4730 - accuracy: 0.6784 - val_loss: 1.1159 - val_accuracy: 0.2339\n",
      "Epoch 28/30\n",
      "38/38 [==============================] - 8s 216ms/step - loss: 0.4394 - accuracy: 0.7030 - val_loss: 1.1351 - val_accuracy: 0.2456\n",
      "Epoch 29/30\n",
      "38/38 [==============================] - 9s 225ms/step - loss: 0.4139 - accuracy: 0.7202 - val_loss: 1.1312 - val_accuracy: 0.2515\n",
      "Epoch 30/30\n",
      "38/38 [==============================] - 8s 209ms/step - loss: 0.3887 - accuracy: 0.7376 - val_loss: 1.1349 - val_accuracy: 0.2632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x42eb82410>"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear any previous session data\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Create the model using the defined architecture\n",
    "model2 = encoder_decoder(encoder_vocab_size, decoder_vocab_size, 39, lstm_size, embedding_dim, att_units, 40, 'concat', dec_units, batch_size)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "\n",
    "# Compile the model with custom loss function and accuracy metric\n",
    "model2.compile(optimizer=optimizer, loss=custom_lossfunction, metrics=[accuracy])\n",
    "\n",
    "# Set the number of training and validation steps\n",
    "train_steps = train_data.shape[0] // 64\n",
    "valid_steps = test_data.shape[0] // 20\n",
    "\n",
    "# Train the model\n",
    "model2.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=test_dataloader, validation_steps=valid_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmjF11J0zJQn"
   },
   "outputs": [],
   "source": [
    "# rlp = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss', factor=0.1, patience=5, verbose=10,\n",
    "#     mode='auto', min_delta=0.00001, cooldown=0, min_lr=0.0001,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DpC9zlzMcXp"
   },
   "source": [
    "## <font color='blue'>**Inference**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5NhESYyMW_t"
   },
   "source": [
    "<font color='blue'>**Plot attention weights**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "id": "pkEY7SsBMtrC"
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "# Beam search decoder function\n",
    "def beam_search_decoder(data, k):\n",
    "    # Initialize sequences with an empty sequence and score 0.0\n",
    "    sequences = [[list(), 0.0]]\n",
    "    \n",
    "    # Loop through each row of data\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        \n",
    "        # Loop through each sequence in sequences\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            \n",
    "            # Loop through each element in the row\n",
    "            for j in range(len(row)):\n",
    "                try:\n",
    "                    # Create a new candidate sequence and update the score\n",
    "                    candidate = [seq + [j], score - log(row[j])]\n",
    "                    all_candidates.append(candidate)\n",
    "                except ValueError as e:\n",
    "                    # If there's an exception, set the candidate score to 0\n",
    "                    candidate = [seq + [j], 0]\n",
    "                    all_candidates.append(candidate)\n",
    "        \n",
    "        # Order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup: tup[1])\n",
    "        \n",
    "        # Select the top k best candidates\n",
    "        sequences = ordered[:k]\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "# Commented version of the code that explains each step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "id": "7g9iUbnHSLRY"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Function to evaluate a given sentence\n",
    "def evaluate(sentence):\n",
    "    max_length_targ = 40\n",
    "    max_length_inp  = 39\n",
    "    \n",
    "    # Initialize an array to store attention weights\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    # Tokenize the sentence using the tokenizer\n",
    "    inputs = tokenizer.texts_to_sequences([sentence])\n",
    "    inputs =  tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=max_length_inp, padding='post') \n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = '' \n",
    "\n",
    "    # Initialize the initial state of the decoder\n",
    "    initial_state = model2.layers[0].initialize_states(batch_size=1)\n",
    "    \n",
    "    # Pass the inputs through the encoder\n",
    "    encoder_outputs, state_h, state_c = model2.layers[0](inputs, initial_state)   \n",
    "    dec_input = tf.expand_dims([tokenizer_e.word_index['<start>']], 0)\n",
    "\n",
    "    # Loop through the decoder steps\n",
    "    for i in range(max_length_targ):\n",
    "        # Get the output, new states, attention weights, and result using oneStepDecoder\n",
    "        Output, state_h, state_c, att_weights, _ = model2.layers[1].oneStepDecoder(dec_input, encoder_outputs, state_h, state_c)\n",
    "        \n",
    "        # Perform Beam Search Decoder\n",
    "        Result_beam_list = beam_search_decoder(Output, k=1)\n",
    "        Result_beam = Result_beam_list[0][0]\n",
    "\n",
    "        # Reshape attention weights and store them\n",
    "        attention_weights = tf.reshape(att_weights, (-1, ))\n",
    "        attention_plot[i] = attention_weights.numpy()\n",
    "\n",
    "        # Get the predicted ID using argmax\n",
    "        predicted_id = tf.argmax(Output[0]).numpy()\n",
    "  \n",
    "        # Update the result string\n",
    "        result += tokenizer_e.index_word[Result_beam[0]] + ' '\n",
    "        \n",
    "        # Check if the end token is predicted\n",
    "        if tokenizer_e.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # Feed the predicted ID back into the model for the next step\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return result, sentence, attention_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UR87eW8lOzt9",
    "outputId": "3721d822-b9e8-46de-b897-8939c53cd050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line retrieves the index of the \"<end>\" token in the word index of the \"tokenizer_e\" tokenizer.\n",
    "tokenizer_e.word_index[\"<end>\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6D07RIJNDvy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to plot attention\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    # Display attention matrix as a heatmap\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    # Set x-axis and y-axis labels using the provided sentences\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    \n",
    "    # Adjust ticks for clarity\n",
    "    ax.xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "id": "c-HIpuKDM88T"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    # result, sentence, attention_plot = evaluate(sentence)\n",
    "    # print('Input: %s' % (sentence))\n",
    "    # print('Predicted translation: {}'.format(result))\n",
    "    # print(\"-\"*50)\n",
    "    # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    # plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "    # return result\n",
    "\n",
    "    # Uncomment the lines below for translation\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    print(\"-\"*50)\n",
    "    # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    # plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path to save the model\n",
    "save_directory = \"/Users/sayedraheel/Desktop/NLP/Sentence_correction\"\n",
    "\n",
    "# Instantiate the encoder_decoder model\n",
    "tf.keras.models.save_model(model2, save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"/Users/sayedraheel/Desktop/NLP/Sentence_correction\"\n",
    "\n",
    "# Save the model\n",
    "#model2.save(save_directory)\n",
    "model2.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxmLpST4NOd5",
    "outputId": "b08cc3ee-93c5-440f-fce9-cae62ba9c43d"
   },
   "outputs": [],
   "source": [
    "# Translating the SMS_TEXT from the test_data dataframe at index 153\n",
    "result = translate(test_data[\"SMS_TEXT\"][153])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYcUAVYae4Oh",
    "outputId": "05f5b370-a61e-4340-c0a2-6c8873b376d6"
   },
   "outputs": [],
   "source": [
    "# Translating the text from test_data at index 488\n",
    "result = translate(test_data[\"SMS_TEXT\"][488])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95ZaIAtGb3k_",
    "outputId": "e8b59c30-8e97-46cf-ed8c-24785cea81a5"
   },
   "outputs": [],
   "source": [
    "# Accessing the word index of the token \"you.\" in the tokenizer\n",
    "tokenizer.word_index[\"you.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4HDPy50OFJC",
    "outputId": "da8aebb3-9286-4a20-bafb-b8f66cbc66fb"
   },
   "outputs": [],
   "source": [
    "# Access the SMS_TEXT column from the test_data DataFrame\n",
    "# This column contains the text messages that we want to analyze\n",
    "sms_text_column = test_data[\"SMS_TEXT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeLarAhIT9VK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXVoNapqXDEy",
    "outputId": "77d9b927-41d1-4c74-8ec4-d4102c7eef2c"
   },
   "outputs": [],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define a function for calculating BLEU score\n",
    "def BleuScore(validation):\n",
    "    # Extract input and true output sentences from validation data\n",
    "    input = list(validation['SMS_TEXT'])\n",
    "    Y_true = list(validation['ENGLISH_OUTPUT'])\n",
    "    \n",
    "    results = []  # Store predicted results\n",
    "    bleuscores = []  # Store BLEU scores\n",
    "    input_sent_list = []  # Store input sentences\n",
    "    \n",
    "    # Loop through each input sentence\n",
    "    for i in tqdm(range(len(input))):\n",
    "        try:\n",
    "            # Call the 'evaluate' function to get the prediction and attention plot\n",
    "            result, sentence, attention_plot = evaluate(input[i])\n",
    "            \n",
    "            results.append(result)  # Store predicted result\n",
    "            input_sent_list.append(sentence)  # Store input sentence\n",
    "            \n",
    "            # Calculate BLEU score for the predicted result and store it\n",
    "            bleuscores.append(bleu.sentence_bleu(Y_true[i], result))\n",
    "        except KeyError as e:\n",
    "            pass  # Skip if there's a KeyError (missing key)\n",
    "    \n",
    "    # Calculate average BLEU score\n",
    "    average_score = sum(bleuscores) / len(bleuscores)\n",
    "    \n",
    "    return average_score, bleuscores, results, input_sent_list\n",
    "\n",
    "# Call the function to calculate BLEU scores\n",
    "AvearageScore, bleuscores, results, input_sent_list = BleuScore(test_data)\n",
    "\n",
    "# Print the average BLEU score\n",
    "print(\"Average Bleuscore:\", AvearageScore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1IhdBrgQYJr"
   },
   "source": [
    "<font color='blue'>**Predict the sentence translation**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "id": "iDT91Im6MZS6"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "      '''\n",
    "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
    "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
    "  C. Initialize index of <\\t> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
    "  D. till we reach max_length of decoder or till the model predicted character <\\n>:\n",
    "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
    "         And get the character using the tokenizer(character index) and then store it in a string.\n",
    "  E. Return the predicted sentence\n",
    "\n",
    "  '''\n",
    "\n",
    "\n",
    "    # Convert the input sentence into integer sequences using the previously used tokenizer\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_sentence])\n",
    "\n",
    "    # Pad the input sequence to match the desired input length\n",
    "    inputs = pad_sequences(input_sequence, maxlen=39, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    units = 100\n",
    "\n",
    "    # Initialize hidden state for the encoder\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "\n",
    "    # Pass the inputs through the encoder and get encoder output, hidden state, and cell state\n",
    "    encoder_output, hidden_state, cell_state = model2.layers[0](inputs, hidden)\n",
    "    dec_hidden = hidden_state\n",
    "\n",
    "    # Initialize the decoder input with the start token\n",
    "    dec_input = tf.expand_dims([tokenizer_e.word_index['<start>']], 0)\n",
    "\n",
    "    # Loop through each time step of the decoder\n",
    "    for t in range(40):\n",
    "        # Use the decoder to generate predictions and update decoder hidden state and cell state\n",
    "        predictions, dec_hidden, cell_state, attention_weights, context_vector = model2.layers[1].oneStepDecoder(dec_input, encoder_output, dec_hidden, cell_state)\n",
    "\n",
    "        # Get the index of the predicted character with the highest probability\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        # Convert the predicted index to the corresponding word and add it to the result string\n",
    "        result += tokenizer_e.index_word[predicted_id] + ' '\n",
    "\n",
    "        # Check if the end token has been predicted, and if so, return the result\n",
    "        if tokenizer_e.word_index['<end>'] == predicted_id:\n",
    "            return result\n",
    "\n",
    "        # Prepare the predicted character for the next time step\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Z-As25YMd47",
    "outputId": "c7587e3c-4ea7-45e4-d3f9-0ee4c18e1987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "i tink i get her flowers,hee... or smting... i wun stay long lar.\n",
      "Prediction\n",
      "Haha. Okay. Are you going to be going for the patio <end> \n",
      "Original Sentence\n",
      "I think I get her flowers. Or something. I want to stay long. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Dinner changed to tm becos xy can't make it on wednesday.\n",
      "Prediction\n",
      "Hello Peach! My Og going. They should be going. They don't want to go out. <end> \n",
      "Original Sentence\n",
      "Dinner have been changed to tomorrow because Xy can't make it on Wednesday. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "found the graphic for t-shirt design. ticket also book already.\n",
      "Prediction\n",
      "I'm in LT24. to see that about my house already. <end> \n",
      "Original Sentence\n",
      "Found the graphic for t-shirt design. Ticket also book already. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Can't u juz give me ur intro 1st plzZz...\n",
      "Prediction\n",
      "You got driving now. I am going to be late. I don't want to go for ideas first. She is not much to buy? <end> \n",
      "Original Sentence\n",
      "Can't you just give me your introduction first? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "6598941248 Got my msg?\n",
      "Prediction\n",
      "Your chauffeur? Hahaha, who is it? From TIBS or SBS? <end> \n",
      "Original Sentence\n",
      "6598941248, got my message? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Hi,hw s evy1?care 2 chat,any1?\n",
      "Prediction\n",
      "I'm at the <end> \n",
      "Original Sentence\n",
      "Hi, how is everyone? Care to chat, anyone? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Ok then when i reach i go collect ticket first. Now i nothing to do watch tv.\n",
      "Prediction\n",
      "What course do you the notes tomorrow? <end> \n",
      "Original Sentence\n",
      "Okay, then when I reach, I will go and collect the tickets first. Now I have nothing to do, so watching TV. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "JESS wat r u workin s\n",
      "Prediction\n",
      "Hello. How is not confirmed. Mich. She is not pouring there, it's pouring at Sentosa. I just sold shots changed to snatch joss sticks. Do you want to go to sms by phone! <end> \n",
      "Original Sentence\n",
      "Jess, what are you working as? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "ICEMAN Hi! you sape nama? boleh kite chat?\n",
      "Prediction\n",
      "Hi! How was your day? <end> \n",
      "Original Sentence\n",
      "Iceman hi! you sape nama? boleh kite chat? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "i got one here, is $78, 128mb, transcend jetflash, u want?\n",
      "Prediction\n",
      "Haha. Okay. Sure. Hehe. Must buy this time. I'm going. Haha. <end> \n",
      "Original Sentence\n",
      "I got one here, is $78, 128MB, Transcend Jetflash, do you want? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "291-297-2660\n",
      "Prediction\n",
      "2901092582 <end> \n",
      "Original Sentence\n",
      "2292979260 <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Where is it?\n",
      "Prediction\n",
      "Can you slim. Meet you all coming to go to sleep hair and tomorrow. <end> \n",
      "Original Sentence\n",
      "Where is it? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "presing wel anerectinces irent\n",
      "Prediction\n",
      "Hi darling, did you want to chat with me a guy? <end> \n",
      "Original Sentence\n",
      "express delivery is very fast <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "hah... i dun mind.we haven got a chance to catch up.wad time? i go ur plc n we go there together?\n",
      "Prediction\n",
      "Yes. But I don't mind. Set. Sigh, I'm not so good. Are you going to sleep now. <end> \n",
      "Original Sentence\n",
      "Haha. I don't mind. We haven't got a chance to catch up. What time? I go to your place and we go there together? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "+46-987-88-00294\n",
      "Prediction\n",
      "No. <end> \n",
      "Original Sentence\n",
      "+246987508002294 <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "hi gal, can ask daddy 2 call me, i can't get thru his handphone, thks\n",
      "Prediction\n",
      "Yup. The weather is a non profit organization <end> \n",
      "Original Sentence\n",
      "Hi girl, can you ask dad to call me, I can't get through his handphone, thanks. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "playe ce is ha he proint\n",
      "Prediction\n",
      "OK. I'll be late. Maybe we can go and ask. <end> \n",
      "Original Sentence\n",
      "space is a high priority <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "do not win the lavay\n",
      "Prediction\n",
      "i do not walk too quickly <end> \n",
      "Original Sentence\n",
      "meet tomorrow in the lavatory <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Im working ... R ü ireena\n",
      "Prediction\n",
      "I'm going for dinner later. I don't know, I'm not going, but she will be going for 5 to take. <end> \n",
      "Original Sentence\n",
      "I'm working. Are you ireena? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Where got cheese cake...\n",
      "Prediction\n",
      "Is it? Are you going to ecp tomorrow after airport? <end> \n",
      "Original Sentence\n",
      "Where got cheese cake? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "You going funan to buy?\n",
      "Prediction\n",
      "You want to go for the piece of Addidas shoes. <end> \n",
      "Original Sentence\n",
      "Are you going to Funan to buy? <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "the dire chas de comaith win\n",
      "Prediction\n",
      "Hi darling, I am very excited <end> \n",
      "Original Sentence\n",
      "round robin scheduling <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Daddy going out tonight... Ü come home urself... Buy rice oredi...\n",
      "Prediction\n",
      "Okay. So I'll meet you at the patio <end> \n",
      "Original Sentence\n",
      "Daddy is going out tonight. You come home yourself. Buy rice already. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Haiz this kind of thing cannot rush wan lah.. Today is my first day only lor.. Must search slowly..dun worry lah.. Will update u lah..\n",
      "Prediction\n",
      "Yes. I will be late. <end> \n",
      "Original Sentence\n",
      "Sigh this kind of thing cannot rush. Today is my first day only. Must search slowly. Don't worry. I will update to you. <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "+22-939-931-1-18\n",
      "Prediction\n",
      "No. <end> \n",
      "Original Sentence\n",
      "+279053128 <end>\n",
      "********************************************************************************************************************************************************************************************************\n",
      "SMS_TEXT\n",
      "Y... U got lobang ar... Ok lor i dun mind but i got lesson until 4 tmr lei...\n",
      "Prediction\n",
      "Haha. Still must be able to meet you. <end> \n",
      "Original Sentence\n",
      "Why? You have chance. Ok, I don't mind but I have lesson until 4 tomorrow. <end>\n"
     ]
    }
   ],
   "source": [
    "# Loop through each index in the test_data\n",
    "for index in range(len(test_data)):\n",
    "    print('*'*200)  # Print a separator line\n",
    "    print(\"SMS_TEXT\")  # Print a label for the SMS_TEXT\n",
    "    print(test_data['SMS_TEXT'].values[index])  # Print the value of SMS_TEXT at the current index\n",
    "    print(\"Prediction\")  # Print a label for the prediction\n",
    "    print(predict(test_data['SMS_TEXT'].values[index]))  # Print the prediction for the SMS_TEXT at the current index\n",
    "    print(\"Original Sentence\")  # Print a label for the original sentence\n",
    "    print(test_data['ENGLISH_OUTPUT'].iloc[index])  # Print the value of ENGLISH_OUTPUT at the current index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BdPFxK6Pasd",
    "outputId": "2fdbd46a-3680-48b4-ed0b-cf173f9cb8d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6780770304835106\n"
     ]
    }
   ],
   "source": [
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "# Initialize a variable to keep track of the total BLEU score\n",
    "sum = 0\n",
    "\n",
    "# Iterate through each data point in the test_data\n",
    "for index in range(len(test_data)):\n",
    "    # Get the reference (ground truth) sentence from the test_data\n",
    "    reference = test_data['ENGLISH_OUTPUT'].iloc[index]\n",
    "    \n",
    "    # Generate a translation using the predict function\n",
    "    translation = predict(test_data['SMS_TEXT'].iloc[index])\n",
    "    \n",
    "    # Calculate the BLEU score for the generated translation compared to the reference\n",
    "    sum += bleu.sentence_bleu(reference, translation)\n",
    "\n",
    "# Calculate the average BLEU score by dividing the sum by the number of data points\n",
    "average_bleu = sum / len(test_data)\n",
    "print(average_bleu)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Attention_Word_New.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
